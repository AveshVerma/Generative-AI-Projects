{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Generative AI Inferencing APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.path.append(\"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from api_tokens import keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Huggingface API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_token = keys.get(\"huggingface\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Google Gemma "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_URL = \"https://api-inference.huggingface.co/models/\"\n",
    "model_id = \"google/gemma-7b\"\n",
    "gemma_url = API_URL+model_id\n",
    "headers = {\"Authorization\": f\"Bearer {hf_token}\"}\n",
    "\n",
    "def query(payload):\n",
    "    response = requests.post(gemma_url, headers=headers, json=payload)\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_prompt = \"Can you tell me the capital of india?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can you tell me the capital of india? A country whose name pride with his heritage New Delhi.The charming capital of India - The national capital. As long as you do not beat me bloom on your memory.\n",
      "\n",
      "During the coming days you have many appointments with this beautiful city , and here is one of my favorites ! Quick it's a pretty place. Its cultural heritage that side patriotic. And sounds graceful. I just get pleasure in come in this place. Go thank you very much for your treasure-trove of historical monuments.\n"
     ]
    }
   ],
   "source": [
    "res = query({\n",
    "    \"inputs\":input_prompt,\n",
    "})\n",
    "print(res[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zephyrus Beta Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_URL = \"https://api-inference.huggingface.co/models/\"\n",
    "model_id = \"HuggingFaceH4/zephyr-7b-beta\"\n",
    "gemma_url = API_URL+model_id\n",
    "headers = {\"Authorization\": f\"Bearer {hf_token}\"}\n",
    "\n",
    "def query(payload):\n",
    "    response = requests.post(gemma_url, headers=headers, json=payload)\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_prompt = \"Koi BKL hi hoga.... complete this\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Koi BKL hi hoga.... complete this statement in your mind. Yes, that's the first thing either the person talks about or asks you about if/when you returned from Japan. They're not joking or kidding on this topic. Your face looks slightly different when you're back from Japan. You smile more, you're more patient, you're a better person (or something like that). Japanese culture teaches you basic human values, etiquette or whatever you wish to call it. Be it,\n"
     ]
    }
   ],
   "source": [
    "res = query({\n",
    "    \"inputs\":input_prompt,\n",
    "})\n",
    "print(res[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAI API ( GPT Family )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_token = keys.get(\"openai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gemini API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_token = keys.get(\"gemini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
